{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b73fdb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# --------------------\n",
    "# 1. Load Dataset\n",
    "# --------------------\n",
    "df = pd.read_csv('chronickidneydisease.csv')\n",
    "\n",
    "# Example: Adjust column names if they have spaces\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Define target & features\n",
    "target = 'class'  # Adjust if your target column is named differently\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# If target is categorical like 'ckd'/'notckd', encode to 0/1\n",
    "y = y.replace({'ckd': 1, 'notckd': 0})\n",
    "\n",
    "# Identify column types\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# --------------------\n",
    "# 2. Preprocessing\n",
    "# --------------------\n",
    "# Numeric pipeline: handle missing, then scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical pipeline: handle missing, then one-hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# 3. Full Pipeline with Model\n",
    "# --------------------\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# --------------------\n",
    "# 4. Train-Test Split & Training\n",
    "# --------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --------------------\n",
    "# 5. Evaluate\n",
    "# --------------------\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# --------------------\n",
    "# 6. Save Pipeline & Feature Names\n",
    "# --------------------\n",
    "save_data = {\n",
    "    'pipeline': pipeline,\n",
    "    'feature_names': X.columns.tolist()\n",
    "}\n",
    "joblib.dump(save_data, 'CKD.pkl')\n",
    "\n",
    "print(\"âœ… Model pipeline saved as CKD.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
